# Multi-Order-Decoding
This is an implementation of the paper [Does Higher Order LSTM Have Better Accuracy in Chunking and Named Entity Recognition?][[pdf]](https://arxiv.org/pdf/1711.08231.pdf).

## Environment and Dependency
- Ubuntu 16.04
- Python 2.7
- Tensorflow 1.0 

<br /> 

## Required Files

#### Feature files
The model uses features extracted from original texts. Ignore the feature input in the model if you don't want to use extracted features.

#### Probability Files
The model uses features extracted from original texts. Ignore the feature input in the model if you don't want to use extracted features.
The order-3 LSTM-MOD model uses the probabilities generated by naive order-1 model and naive order-2 model at testing stage. So the probabilities need to be preserved in files. We provide probability files generated in our experiments. You can also get the files by training your own naive order-n models. The naive order-n model is exactly bi-directional lstm with order-n tag set.

## Citation
If you use this code for your research, please cite the paper this code is 
based on: [Does Higher Order LSTM Have Better Accuracy in Chunking and Named Entity Recognition?](https://arxiv.org/pdf/1711.08231.pdf)

```
@article{DBLP:journals/corr/abs-1711-08231,
  author    = {Yi Zhang and Xu Sun and Yang Yang},
  title     = {Does Higher Order {LSTM} Have Better Accuracy in Chunking and Named
               Entity Recognition?},
  journal   = {CoRR},
  volume    = {abs/1711.08231},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.08231},
  archivePrefix = {arXiv},
  eprint    = {1711.08231},
  timestamp = {Sun, 03 Dec 2017 12:38:15 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1711-08231},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
```
